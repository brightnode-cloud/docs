---
title: "Zero GPU Nodes on restart"
sidebarTitle: "Zero GPU Nodes"
description: "What to do when your Node machine has zero GPUs."
---

When you restart a stopped Node, you might see a message telling you that there are "Zero GPU Nodes." This is because there are no GPUs available on the machine where your Node was running.

## Why does this happen?

When you deploy a Node, it's assigned to a GPU on a specific physical machine. This creates a link between your Node and that particular piece of hardware. As long as your Node is running, that GPU is exclusively reserved for you. When you stop your Node, you release that specific GPU, allowing other users to rent it. Your Node's [volume storage](/nodes/storage/types) remains on the physical machine, but the GPU slot becomes available.

If another user rents that GPU while your Node is stopped, the GPU will be occupied when you try to restart. Because your Node is still tied to that original machine, it cannot start with a GPU.

When this happens, Brightnode gives you the option to start the Node with zero GPUs. This is primarily a data recovery feature, allowing you to access your Node's volume disk without access to the GPU.

## What are my options?

If you encounter this situation, you have three choices:

1.  **Start with zero GPUs for data access**: Start the Node without a GPU to access its local storage. This is useful for retrieving files, but the Node will have limited CPU resources and is not suitable for compute tasks. You should use this option to back up or transfer your data before terminating the Node.
2.  **Wait and retry**: You can wait and try to restart the Node again later. The GPU may become available if the other user stops their Node, but there is no guarantee of when that will happen.
3.  **Terminate and redeploy**: If you need a GPU immediately, terminate the current Node and deploy a new one with the same configuration. The new Node will be scheduled on any machine in the Brightnode network with an available GPU of your chosen type.

## How do I prevent this?

The most effective way to avoid this issue is to use **[network volumes](/storage/network-volumes)**.

Network volumes decouple your data from a specific physical machine. Your `/workspace` data is stored on a separate, persistent volume that can be attached to any Node. If you need to terminate a Node, you can simply deploy a new one and attach the same network volume, giving you immediate access to your data on a new machine with an available GPU.